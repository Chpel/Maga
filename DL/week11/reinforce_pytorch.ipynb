{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiW8vjlfC6Wn"
      },
      "source": [
        "# REINFORCE in PyTorch\n",
        "\n",
        "Just like we did before for Q-learning, this time we'll design a PyTorch network to learn `CartPole-v0` via policy gradient (REINFORCE).\n",
        "\n",
        "Most of the code in this notebook is taken from approximate Q-learning, so you'll find it more or less familiar and even simpler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfUamtcfC6Wp"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "    !pip install -q gymnasium\n",
        "    !pip install moviepy\n",
        "    !apt install ffmpeg\n",
        "    !pip install imageio-ffmpeg\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq0kA0-XC6Wq"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP7fP4Z9C6Wr"
      },
      "outputs": [],
      "source": [
        "# also you need to install ffmpeg if not installed\n",
        "# for MacOS: ! brew install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7OtTwMlC6Wr"
      },
      "source": [
        "A caveat: with some versions of `pyglet`, the following cell may crash with `NameError: name 'base' is not defined`. The corresponding bug report is [here](https://github.com/pyglet/pyglet/issues/134). If you see this error, try restarting the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "GwLWu_oYC6Wr",
        "outputId": "d0fc27e6-8c77-43fd-972a-b14d49ceae33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d1ea67cc6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoNElEQVR4nO3df3RU9Z3/8dfk1wiEmRggmaQkiIJAhGALGGZtXVpSwg9dWeP5qmUBWw4c2cRTiKWYLlWxe4yLe9YfrcLZs11xz5Fi6REtVFAECWsNiClZfkkqHHaDJZOgNDMETSCZz/cPl9mORGCSkPuZ5Pk4556TuZ/PzLzv5+TMvM7nfu4dlzHGCAAAwCIJThcAAADwZQQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdRwPK888/r+uuu07XXHONCgoK9P777ztZDgAAsIRjAeWVV15RWVmZHn30Uf3hD3/Q+PHjVVRUpMbGRqdKAgAAlnA59WOBBQUFmjRpkn7xi19IksLhsHJycvTggw/q4YcfdqIkAABgiSQn3vTcuXOqrq5WeXl5ZF9CQoIKCwtVVVV1Uf/W1la1trZGHofDYZ0+fVqDBg2Sy+XqkZoBAEDXGGN05swZZWdnKyHh0idxHAkon3zyidrb25WZmRm1PzMzU0eOHLmof0VFhVauXNlT5QEAgKvoxIkTGjp06CX7OBJQYlVeXq6ysrLI42AwqNzcXJ04cUIej8fBygAAwJUKhULKycnRwIEDL9vXkYAyePBgJSYmqqGhIWp/Q0ODfD7fRf3dbrfcbvdF+z0eDwEFAIA4cyXLMxy5iiclJUUTJkzQ9u3bI/vC4bC2b98uv9/vREkAAMAijp3iKSsr0/z58zVx4kTdcssteuaZZ3T27Fl9//vfd6okAABgCccCyj333KNTp07pkUceUSAQ0M0336ytW7detHAWAAD0PY7dB6UrQqGQvF6vgsEga1AAAIgTsXx/81s8AADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADW6faA8thjj8nlckVto0ePjrS3tLSopKREgwYNUmpqqoqLi9XQ0NDdZQAAgDh2VWZQbrrpJtXX10e2d999N9K2dOlSbdq0SRs2bFBlZaVOnjypu+6662qUAQAA4lTSVXnRpCT5fL6L9geDQf3yl7/UunXr9J3vfEeS9OKLL2rMmDHavXu3Jk+efDXKAQAAceaqzKB89NFHys7O1vXXX685c+aorq5OklRdXa3z58+rsLAw0nf06NHKzc1VVVXVV75ea2urQqFQ1AYAAHqvbg8oBQUFWrt2rbZu3arVq1fr+PHj+ta3vqUzZ84oEAgoJSVFaWlpUc/JzMxUIBD4ytesqKiQ1+uNbDk5Od1dNgAAsEi3n+KZMWNG5O/8/HwVFBRo2LBh+vWvf61+/fp16jXLy8tVVlYWeRwKhQgpAAD0Ylf9MuO0tDTdeOONOnr0qHw+n86dO6empqaoPg0NDR2uWbnA7XbL4/FEbQAAoPe66gGlublZx44dU1ZWliZMmKDk5GRt37490l5bW6u6ujr5/f6rXQoAAIgT3X6K50c/+pHuuOMODRs2TCdPntSjjz6qxMRE3XffffJ6vVqwYIHKysqUnp4uj8ejBx98UH6/nyt4AABARLcHlI8//lj33XefPv30Uw0ZMkTf/OY3tXv3bg0ZMkSS9PTTTyshIUHFxcVqbW1VUVGRXnjhhe4uAwAAxDGXMcY4XUSsQqGQvF6vgsEg61EAAIgTsXx/81s8AADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrxBxQdu3apTvuuEPZ2dlyuVx67bXXotqNMXrkkUeUlZWlfv36qbCwUB999FFUn9OnT2vOnDnyeDxKS0vTggUL1Nzc3KUDAQAAvUfMAeXs2bMaP368nn/++Q7bV61apeeee05r1qzRnj17NGDAABUVFamlpSXSZ86cOTp06JC2bdumzZs3a9euXVq0aFHnjwIAAPQqLmOM6fSTXS5t3LhRs2fPlvTF7El2drYeeugh/ehHP5IkBYNBZWZmau3atbr33nv14YcfKi8vT3v37tXEiRMlSVu3btXMmTP18ccfKzs7+7LvGwqF5PV6FQwG5fF4Ols+AADoQbF8f3frGpTjx48rEAiosLAwss/r9aqgoEBVVVWSpKqqKqWlpUXCiSQVFhYqISFBe/bs6fB1W1tbFQqFojYAANB7dWtACQQCkqTMzMyo/ZmZmZG2QCCgjIyMqPakpCSlp6dH+nxZRUWFvF5vZMvJyenOsgEAgGXi4iqe8vJyBYPByHbixAmnSwIAAFdRtwYUn88nSWpoaIja39DQEGnz+XxqbGyMam9ra9Pp06cjfb7M7XbL4/FEbQAAoPfq1oAyfPhw+Xw+bd++PbIvFAppz5498vv9kiS/36+mpiZVV1dH+uzYsUPhcFgFBQXdWQ4AAIhTSbE+obm5WUePHo08Pn78uGpqapSenq7c3FwtWbJE//iP/6iRI0dq+PDh+ulPf6rs7OzIlT5jxozR9OnTtXDhQq1Zs0bnz59XaWmp7r333iu6ggcAAPR+MQeUDz74QN/+9rcjj8vKyiRJ8+fP19q1a/XjH/9YZ8+e1aJFi9TU1KRvfvOb2rp1q6655prIc15++WWVlpZq6tSpSkhIUHFxsZ577rluOBwAANAbdOk+KE7hPigAAMQfx+6DAgAA0B0IKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArBNzQNm1a5fuuOMOZWdny+Vy6bXXXotqv//+++VyuaK26dOnR/U5ffq05syZI4/Ho7S0NC1YsEDNzc1dOhAAANB7xBxQzp49q/Hjx+v555//yj7Tp09XfX19ZPvVr34V1T5nzhwdOnRI27Zt0+bNm7Vr1y4tWrQo9uoBAECvlBTrE2bMmKEZM2Zcso/b7ZbP5+uw7cMPP9TWrVu1d+9eTZw4UZL085//XDNnztQ///M/Kzs7O9aSAABAL3NV1qDs3LlTGRkZGjVqlBYvXqxPP/000lZVVaW0tLRIOJGkwsJCJSQkaM+ePR2+Xmtrq0KhUNQGAAB6r24PKNOnT9d//Md/aPv27fqnf/onVVZWasaMGWpvb5ckBQIBZWRkRD0nKSlJ6enpCgQCHb5mRUWFvF5vZMvJyenusgEAgEViPsVzOffee2/k73Hjxik/P1833HCDdu7cqalTp3bqNcvLy1VWVhZ5HAqFCCkAAPRiV/0y4+uvv16DBw/W0aNHJUk+n0+NjY1Rfdra2nT69OmvXLfidrvl8XiiNgAA0Htd9YDy8ccf69NPP1VWVpYkye/3q6mpSdXV1ZE+O3bsUDgcVkFBwdUuBwAAxIGYT/E0NzdHZkMk6fjx46qpqVF6errS09O1cuVKFRcXy+fz6dixY/rxj3+sESNGqKioSJI0ZswYTZ8+XQsXLtSaNWt0/vx5lZaW6t577+UKHgAAIElyGWNMLE/YuXOnvv3tb1+0f/78+Vq9erVmz56tffv2qampSdnZ2Zo2bZp+9rOfKTMzM9L39OnTKi0t1aZNm5SQkKDi4mI999xzSk1NvaIaQqGQvF6vgsEgp3sAAIgTsXx/xxxQbEBAAQAg/sTy/c1v8QAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdWL+sUAA6C7GGB19a7VMuP2S/a7/zg+U5B7QQ1UBsAEBBYCjgicOyrS3XbJP+Pw5mZT+crlcPVQVAKdxigeA9Yy59AwLgN6HgALAeiYcdroEAD2MgALAepdbowKg9yGgALAeMyhA30NAAWA91qAAfQ8BBYD1OMUD9D0EFADW4xQP0PcQUABYjxkUoO8hoACwn2EGBehrCCgArMcMCtD3EFAAWI81KEDfQ0ABYD0uMwb6HgIKAOsxgwL0PQQUANZjBgXoewgoAKzHIlmg7yGgALAeAQXoewgoAKzHGhSg7yGgALAeAQXoe2IKKBUVFZo0aZIGDhyojIwMzZ49W7W1tVF9WlpaVFJSokGDBik1NVXFxcVqaGiI6lNXV6dZs2apf//+ysjI0LJly9TW1tb1owHQK3GKB+h7YgoolZWVKikp0e7du7Vt2zadP39e06ZN09mzZyN9li5dqk2bNmnDhg2qrKzUyZMnddddd0Xa29vbNWvWLJ07d07vvfeeXnrpJa1du1aPPPJI9x0VgN6Fq3iAPsdljDGdffKpU6eUkZGhyspK3XbbbQoGgxoyZIjWrVunu+++W5J05MgRjRkzRlVVVZo8ebK2bNmi22+/XSdPnlRmZqYkac2aNVq+fLlOnTqllJSUy75vKBSS1+tVMBiUx+PpbPkAHGaMUfUvS2TaLz2DOrSgWL7x0+RyuXqoMgBXQyzf311agxIMBiVJ6enpkqTq6mqdP39ehYWFkT6jR49Wbm6uqqqqJElVVVUaN25cJJxIUlFRkUKhkA4dOtTh+7S2tioUCkVtAPoOw48FAn1OpwNKOBzWkiVLdOutt2rs2LGSpEAgoJSUFKWlpUX1zczMVCAQiPT5y3Byof1CW0cqKirk9XojW05OTmfLBhCHTDuneIC+ptMBpaSkRAcPHtT69eu7s54OlZeXKxgMRrYTJ05c9fcEYA8WyQJ9T6cCSmlpqTZv3qx33nlHQ4cOjez3+Xw6d+6cmpqaovo3NDTI5/NF+nz5qp4Ljy/0+TK32y2PxxO1AegdktwDLtvnfMuZHqgEgE1iCijGGJWWlmrjxo3asWOHhg8fHtU+YcIEJScna/v27ZF9tbW1qqurk9/vlyT5/X4dOHBAjY2NkT7btm2Tx+NRXl5eV44FQBwaPOrWy/b59I9VPVAJAJskxdK5pKRE69at0+uvv66BAwdG1ox4vV7169dPXq9XCxYsUFlZmdLT0+XxePTggw/K7/dr8uTJkqRp06YpLy9Pc+fO1apVqxQIBLRixQqVlJTI7XZ3/xECsJorgftFArhYTAFl9erVkqQpU6ZE7X/xxRd1//33S5KefvppJSQkqLi4WK2trSoqKtILL7wQ6ZuYmKjNmzdr8eLF8vv9GjBggObPn6/HH3+8a0cCIC65EhKdLgGAhbp0HxSncB8UoHcwxqi+Zqv+9P7GS/ZzJSZrwoJfcB8UIM712H1QAKCrmEEB0BECCgBHsQYFQEf4ZADgKJeLGRQAFyOgAHAUp3gAdISAAsBRnOIB0BE+GQA4ihkUAB0hoABwlMvFxxCAi/HJAMBRzKAA6AgBBYCjCCgAOkJAAeAsTvEA6ACfDAAcxQwKgI4QUAA4isuMAXSETwYAjmIGBUBHCCgAHEVAAdARAgoAR/FbPAA6QkAB4CzWoADoAJ8MABzFnWQBdIRPBgCOYg0KgI4QUAA4ioACoCMEFACO4j4oADrCJwMAR7EGBUBH+GQA4BiXy8UpHgAdIqAAiAsm3O50CQB6EAEFQHwwYacrANCDCCgA4oIJE1CAvoSAAiAuGMMpHqAvIaAAiAOGGRSgjyGgAIgLhjUoQJ9CQAEQH5hBAfoUAgqAuMBlxkDfQkABEBdYJAv0LTEFlIqKCk2aNEkDBw5URkaGZs+erdra2qg+U6ZM+eLukH+xPfDAA1F96urqNGvWLPXv318ZGRlatmyZ2traun40AHonw2XGQF+TFEvnyspKlZSUaNKkSWpra9NPfvITTZs2TYcPH9aAAQMi/RYuXKjHH3888rh///6Rv9vb2zVr1iz5fD699957qq+v17x585ScnKwnnniiGw4JQG/EKR6gb4kpoGzdujXq8dq1a5WRkaHq6mrddtttkf39+/eXz+fr8DXeeustHT58WG+//bYyMzN1880362c/+5mWL1+uxx57TCkpKZ04DAC9HVfxAH1Ll9agBINBSVJ6enrU/pdfflmDBw/W2LFjVV5ers8++yzSVlVVpXHjxikzMzOyr6ioSKFQSIcOHerwfVpbWxUKhaI2AH0Mp3iAPiWmGZS/FA6HtWTJEt16660aO3ZsZP/3vvc9DRs2TNnZ2dq/f7+WL1+u2tpavfrqq5KkQCAQFU4kRR4HAoEO36uiokIrV67sbKkA4p7hFA/Qx3Q6oJSUlOjgwYN69913o/YvWrQo8ve4ceOUlZWlqVOn6tixY7rhhhs69V7l5eUqKyuLPA6FQsrJyelc4QDiEqd4gL6lU6d4SktLtXnzZr3zzjsaOnToJfsWFBRIko4ePSpJ8vl8amhoiOpz4fFXrVtxu93yeDxRG4C+hat4gL4lpoBijFFpaak2btyoHTt2aPjw4Zd9Tk1NjSQpKytLkuT3+3XgwAE1NjZG+mzbtk0ej0d5eXmxlAOgD+EUD9C3xHSKp6SkROvWrdPrr7+ugQMHRtaMeL1e9evXT8eOHdO6des0c+ZMDRo0SPv379fSpUt12223KT8/X5I0bdo05eXlae7cuVq1apUCgYBWrFihkpISud3u7j9CAL0CN2oD+paYZlBWr16tYDCoKVOmKCsrK7K98sorkqSUlBS9/fbbmjZtmkaPHq2HHnpIxcXF2rRpU+Q1EhMTtXnzZiUmJsrv9+vv/u7vNG/evKj7pgDAl3GKB+hbYppBMcZcsj0nJ0eVlZWXfZ1hw4bpjTfeiOWtAfRxLJIF+hZ+iwdAXGAGBehbCCgA4gOLZIE+hYACIC6wSBboWwgoAOxnDKd4gD6GgALAekYskgX6GgIKAEclJrt17fUTL93JhPXJkXcv3QdAr0JAAeAsl0sJySmX7RZuO9cDxQCwBQEFgONcLj6KAETjUwGAw1xyJSQ6XQQAyxBQADjO5XI5XQIAyxBQADjO5WIGBUA0AgoAh7kk1qAA+BI+FQA4yyW5EvgoAhCNTwUAjnKJgALgYnwqAHAep3gAfAmfCgAcxmXGAC5GQAHgLBc3agNwMT4VADiPgALgS/hUAOAwF4tkAVwkyekCAMS/tra2Tj/XhNtkzBX0M117H0lKSEhQAmEIiAsEFABdNmrUKNXV1XXquUmJCbrz1hv10P/zX7LfwYMH9I05/Tr1Hhds2rRJ06dP79JrAOgZBBQAXdbW1tbp2Q0Tdunc+cs/1xjT5RkUcyVTNQCsQEAB4Lj28P8Fh0/OZSvYNkRhJapfQrOGpNTJndDiYHUAnEBAAeAoIykcDkuSjn72DX3ccqNawgNk5FKy65w+bhmlb3jecrZIAD2O1WIAnGWktrB0/PNxOvbZzfo87JFRoqQEnTfX6M9tWXqv6S6FDTdzA/oSAgoAxzW2ZOvI2ckKf8Wk7ufhVFUFZ/dsUQAcRUAB4Cgj879rUFyX6OWSuWQ7gN6GgALAWUZq/981KABwAQEFgKOMoq/iAQCJgALAAmmJH2tE/w/kUsczKcmuFhV4N/VwVQCcFFNAWb16tfLz8+XxeOTxeOT3+7Vly5ZIe0tLi0pKSjRo0CClpqaquLhYDQ0NUa9RV1enWbNmqX///srIyNCyZcu6fPMlAHEu3K4R/f6g6/odUIrrs/8NKkaJrnNKTTyt2659RcmuVqerBNCDYroPytChQ/Xkk09q5MiRMsbopZde0p133ql9+/bppptu0tKlS/W73/1OGzZskNfrVWlpqe666y79/ve/lyS1t7dr1qxZ8vl8eu+991RfX6958+YpOTlZTzzxxFU5QAD2C/y5Wa///oikI2povU5/bvOp3SSpf2JQ2e5jeiPhMzX++azTZQLoQS7TxXs/p6en66mnntLdd9+tIUOGaN26dbr77rslSUeOHNGYMWNUVVWlyZMna8uWLbr99tt18uRJZWZmSpLWrFmj5cuX69SpU0pJSbmi9wyFQvJ6vbr//vuv+DkArp5169apubnZ6TIua8aMGcrJyXG6DKDPOnfunNauXatgMCiPx3PJvp2+k2x7e7s2bNigs2fPyu/3q7q6WufPn1dhYWGkz+jRo5WbmxsJKFVVVRo3blwknEhSUVGRFi9erEOHDunrX/96h+/V2tqq1tb/m94NhUKSpLlz5yo1NbWzhwCgm/z2t7+Ni4BSVFQkv//SP0oI4Oppbm7W2rVrr6hvzAHlwIED8vv9amlpUWpqqjZu3Ki8vDzV1NQoJSVFaWlpUf0zMzMVCAQkSYFAICqcXGi/0PZVKioqtHLlyov2T5w48bIJDMDVFy8zmTfeeKNuueUWp8sA+qwLEwxXIuareEaNGqWamhrt2bNHixcv1vz583X48OFYXyYm5eXlCgaDke3EiRNX9f0AAICzYp5BSUlJ0YgRIyRJEyZM0N69e/Xss8/qnnvu0blz59TU1BQ1i9LQ0CCfzydJ8vl8ev/996Ne78JVPhf6dMTtdsvtdsdaKgAAiFNdvg9KOBxWa2urJkyYoOTkZG3fvj3SVltbq7q6usg5X7/frwMHDqixsTHSZ9u2bfJ4PMrLy+tqKQAAoJeIaQalvLxcM2bMUG5urs6cOaN169Zp586devPNN+X1erVgwQKVlZUpPT1dHo9HDz74oPx+vyZPnixJmjZtmvLy8jR37lytWrVKgUBAK1asUElJCTMkAAAgIqaA0tjYqHnz5qm+vl5er1f5+fl688039d3vfleS9PTTTyshIUHFxcVqbW1VUVGRXnjhhcjzExMTtXnzZi1evFh+v18DBgzQ/Pnz9fjjj3fvUQEAgLjW5fugOOHCfVCu5DpqAFffsGHDVFdX53QZl/XGG29oxowZTpcB9FmxfH/zWzwAAMA6BBQAAGAdAgoAALAOAQUAAFin07/FAwAXFBUV6dSpU06XcVlf/qkNAPYioADosn/91391ugQAvQyneAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOvEFFBWr16t/Px8eTweeTwe+f1+bdmyJdI+ZcoUuVyuqO2BBx6Ieo26ujrNmjVL/fv3V0ZGhpYtW6a2trbuORoAANArJMXSeejQoXryySc1cuRIGWP00ksv6c4779S+fft00003SZIWLlyoxx9/PPKc/v37R/5ub2/XrFmz5PP59N5776m+vl7z5s1TcnKynnjiiW46JAAAEO9cxhjTlRdIT0/XU089pQULFmjKlCm6+eab9cwzz3TYd8uWLbr99tt18uRJZWZmSpLWrFmj5cuX69SpU0pJSbmi9wyFQvJ6vQoGg/J4PF0pHwAA9JBYvr87vQalvb1d69ev19mzZ+X3+yP7X375ZQ0ePFhjx45VeXm5Pvvss0hbVVWVxo0bFwknklRUVKRQKKRDhw595Xu1trYqFApFbQAAoPeK6RSPJB04cEB+v18tLS1KTU3Vxo0blZeXJ0n63ve+p2HDhik7O1v79+/X8uXLVVtbq1dffVWSFAgEosKJpMjjQCDwle9ZUVGhlStXxloqAACIUzEHlFGjRqmmpkbBYFC/+c1vNH/+fFVWViovL0+LFi2K9Bs3bpyysrI0depUHTt2TDfccEOniywvL1dZWVnkcSgUUk5OTqdfDwAA2C3mUzwpKSkaMWKEJkyYoIqKCo0fP17PPvtsh30LCgokSUePHpUk+Xw+NTQ0RPW58Njn833le7rd7siVQxc2AADQe3X5PijhcFitra0dttXU1EiSsrKyJEl+v18HDhxQY2NjpM+2bdvk8Xgip4kAAABiOsVTXl6uGTNmKDc3V2fOnNG6deu0c+dOvfnmmzp27JjWrVunmTNnatCgQdq/f7+WLl2q2267Tfn5+ZKkadOmKS8vT3PnztWqVasUCAS0YsUKlZSUyO12X5UDBAAA8SemgNLY2Kh58+apvr5eXq9X+fn5evPNN/Xd735XJ06c0Ntvv61nnnlGZ8+eVU5OjoqLi7VixYrI8xMTE7V582YtXrxYfr9fAwYM0Pz586PumwIAANDl+6A4gfugAAAQf3rkPigAAABXCwEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALBOktMFdIYxRpIUCoUcrgQAAFypC9/bF77HLyUuA8qZM2ckSTk5OQ5XAgAAYnXmzBl5vd5L9nGZK4kxlgmHw6qtrVVeXp5OnDghj8fjdElxKxQKKScnh3HsBoxl92Esuwfj2H0Yy+5hjNGZM2eUnZ2thIRLrzKJyxmUhIQEfe1rX5MkeTwe/lm6AePYfRjL7sNYdg/Gsfswll13uZmTC1gkCwAArENAAQAA1onbgOJ2u/Xoo4/K7XY7XUpcYxy7D2PZfRjL7sE4dh/GsufF5SJZAADQu8XtDAoAAOi9CCgAAMA6BBQAAGAdAgoAALBOXAaU559/Xtddd52uueYaFRQU6P3333e6JOvs2rVLd9xxh7Kzs+VyufTaa69FtRtj9MgjjygrK0v9+vVTYWGhPvroo6g+p0+f1pw5c+TxeJSWlqYFCxaoubm5B4/CeRUVFZo0aZIGDhyojIwMzZ49W7W1tVF9WlpaVFJSokGDBik1NVXFxcVqaGiI6lNXV6dZs2apf//+ysjI0LJly9TW1taTh+Ko1atXKz8/P3KTK7/fry1btkTaGcPOe/LJJ+VyubRkyZLIPsbzyjz22GNyuVxR2+jRoyPtjKPDTJxZv369SUlJMf/+7/9uDh06ZBYuXGjS0tJMQ0OD06VZ5Y033jD/8A//YF599VUjyWzcuDGq/cknnzRer9e89tpr5r/+67/M3/zN35jhw4ebzz//PNJn+vTpZvz48Wb37t3mP//zP82IESPMfffd18NH4qyioiLz4osvmoMHD5qamhozc+ZMk5uba5qbmyN9HnjgAZOTk2O2b99uPvjgAzN58mTzV3/1V5H2trY2M3bsWFNYWGj27dtn3njjDTN48GBTXl7uxCE54re//a353e9+Z/74xz+a2tpa85Of/MQkJyebgwcPGmMYw856//33zXXXXWfy8/PND3/4w8h+xvPKPProo+amm24y9fX1ke3UqVORdsbRWXEXUG655RZTUlISedze3m6ys7NNRUWFg1XZ7csBJRwOG5/PZ5566qnIvqamJuN2u82vfvUrY4wxhw8fNpLM3r17I322bNliXC6X+dOf/tRjtdumsbHRSDKVlZXGmC/GLTk52WzYsCHS58MPPzSSTFVVlTHmi7CYkJBgAoFApM/q1auNx+Mxra2tPXsAFrn22mvNv/3bvzGGnXTmzBkzcuRIs23bNvPXf/3XkYDCeF65Rx991IwfP77DNsbReXF1iufcuXOqrq5WYWFhZF9CQoIKCwtVVVXlYGXx5fjx4woEAlHj6PV6VVBQEBnHqqoqpaWlaeLEiZE+hYWFSkhI0J49e3q8ZlsEg0FJUnp6uiSpurpa58+fjxrL0aNHKzc3N2osx40bp8zMzEifoqIihUIhHTp0qAert0N7e7vWr1+vs2fPyu/3M4adVFJSolmzZkWNm8T/ZKw++ugjZWdn6/rrr9ecOXNUV1cniXG0QVz9WOAnn3yi9vb2qH8GScrMzNSRI0ccqir+BAIBSepwHC+0BQIBZWRkRLUnJSUpPT090qevCYfDWrJkiW699VaNHTtW0hfjlJKSorS0tKi+Xx7Ljsb6QltfceDAAfn9frW0tCg1NVUbN25UXl6eampqGMMYrV+/Xn/4wx+0d+/ei9r4n7xyBQUFWrt2rUaNGqX6+nqtXLlS3/rWt3Tw4EHG0QJxFVAAJ5WUlOjgwYN69913nS4lLo0aNUo1NTUKBoP6zW9+o/nz56uystLpsuLOiRMn9MMf/lDbtm3TNddc43Q5cW3GjBmRv/Pz81VQUKBhw4bp17/+tfr16+dgZZDi7CqewYMHKzEx8aJV1A0NDfL5fA5VFX8ujNWlxtHn86mxsTGqva2tTadPn+6TY11aWqrNmzfrnXfe0dChQyP7fT6fzp07p6ampqj+Xx7Ljsb6QltfkZKSohEjRmjChAmqqKjQ+PHj9eyzzzKGMaqurlZjY6O+8Y1vKCkpSUlJSaqsrNRzzz2npKQkZWZmMp6dlJaWphtvvFFHjx7l/9ICcRVQUlJSNGHCBG3fvj2yLxwOa/v27fL7/Q5WFl+GDx8un88XNY6hUEh79uyJjKPf71dTU5Oqq6sjfXbs2KFwOKyCgoIer9kpxhiVlpZq48aN2rFjh4YPHx7VPmHCBCUnJ0eNZW1trerq6qLG8sCBA1GBb9u2bfJ4PMrLy+uZA7FQOBxWa2srYxijqVOn6sCBA6qpqYlsEydO1Jw5cyJ/M56d09zcrGPHjikrK4v/Sxs4vUo3VuvXrzdut9usXbvWHD582CxatMikpaVFraLGFyv89+3bZ/bt22ckmX/5l38x+/btM//zP/9jjPniMuO0tDTz+uuvm/3795s777yzw8uMv/71r5s9e/aYd99914wcObLPXWa8ePFi4/V6zc6dO6MuRfzss88ifR544AGTm5trduzYYT744APj9/uN3++PtF+4FHHatGmmpqbGbN261QwZMqRPXYr48MMPm8rKSnP8+HGzf/9+8/DDDxuXy2XeeustYwxj2FV/eRWPMYznlXrooYfMzp07zfHjx83vf/97U1hYaAYPHmwaGxuNMYyj0+IuoBhjzM9//nOTm5trUlJSzC233GJ2797tdEnWeeedd4yki7b58+cbY7641PinP/2pyczMNG6320ydOtXU1tZGvcann35q7rvvPpOammo8Ho/5/ve/b86cOePA0TinozGUZF588cVIn88//9z8/d//vbn22mtN//79zd/+7d+a+vr6qNf57//+bzNjxgzTr18/M3jwYPPQQw+Z8+fP9/DROOcHP/iBGTZsmElJSTFDhgwxU6dOjYQTYxjDrvpyQGE8r8w999xjsrKyTEpKivna175m7rnnHnP06NFIO+PoLJcxxjgzdwMAANCxuFqDAgAA+gYCCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACs8/8Bz7imrUDUvvoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "\n",
        "# gym compatibility: unwrap TimeLimit\n",
        "if hasattr(env, '_max_episode_steps'):\n",
        "    env = env.env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "plt.imshow(env.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_Uf45qBC6Ws"
      },
      "source": [
        "# Building the network for REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZk1Z7tfC6Ws"
      },
      "source": [
        "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n",
        "\n",
        "For numerical stability, please __do not include the softmax layer into your network architecture__.\n",
        "We'll use softmax or log-softmax where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEQyNiKOC6Ws"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeUajQRTC6Ws"
      },
      "outputs": [],
      "source": [
        "# Build a simple neural network that predicts policy logits.\n",
        "# Keep it simple: CartPole isn't worth deep architectures.\n",
        "model = nn.Sequential(\n",
        "  nn.Linear(state_dim[0], 32),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(32,64),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(64,n_actions)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGWXokD8C6Ws"
      },
      "source": [
        "#### Predict function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQJcgdr0C6Ws"
      },
      "source": [
        "Note: output value of this function is not a torch tensor, it's a numpy array.\n",
        "So, here gradient calculation is not needed.\n",
        "<br>\n",
        "Use [no_grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad)\n",
        "to suppress gradient calculation.\n",
        "<br>\n",
        "Also, `.detach()` (or legacy `.data` property) can be used instead, but there is a difference:\n",
        "<br>\n",
        "With `.detach()` computational graph is built but then disconnected from a particular tensor,\n",
        "so `.detach()` should be used if that graph is needed for backprop via some other (not detached) tensor;\n",
        "<br>\n",
        "In contrast, no graph is built by any operation in `no_grad()` context, thus it's preferable here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ1hXrxeC6Ws"
      },
      "outputs": [],
      "source": [
        "def predict_probs(states):\n",
        "    \"\"\"\n",
        "    Predict action probabilities given states.\n",
        "    :param states: numpy array of shape [batch, state_shape]\n",
        "    :returns: numpy array of shape [batch, n_actions]\n",
        "    \"\"\"\n",
        "    # convert states, compute logits, use softmax to get probability\n",
        "    states = torch.tensor(states)\n",
        "    with torch.no_grad():\n",
        "        logits = model(states)\n",
        "    return np.array(F.softmax(logits, dim=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9C92QdFC6Wt"
      },
      "outputs": [],
      "source": [
        "test_states = np.array([env.reset()[0] for _ in range(5)])\n",
        "test_probas = predict_probs(test_states)\n",
        "assert isinstance(test_probas, np.ndarray), \\\n",
        "    \"you must return np array and not %s\" % type(test_probas)\n",
        "assert tuple(test_probas.shape) == (test_states.shape[0], env.action_space.n), \\\n",
        "    \"wrong output shape: %s\" % np.shape(test_probas)\n",
        "assert np.allclose(np.sum(test_probas, axis=1), 1), \"probabilities do not sum to 1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOOt3ZWDC6Wt"
      },
      "source": [
        "### Play the game\n",
        "\n",
        "We can now use our newly built agent to play the game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFcsCCCOC6Wt"
      },
      "outputs": [],
      "source": [
        "def generate_session(env, t_max=1000):\n",
        "    \"\"\"\n",
        "    Play a full session with REINFORCE agent.\n",
        "    Returns sequences of states, actions, and rewards.\n",
        "    \"\"\"\n",
        "    # arrays to record session\n",
        "    states, actions, rewards = [], [], []\n",
        "\n",
        "    s = env.reset()[0]\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # action probabilities array aka pi(a|s)\n",
        "        action_probs = predict_probs(np.array([s]))[0]\n",
        "\n",
        "        # Sample action with given probabilities.\n",
        "        a = np.argmax(action_probs)\n",
        "\n",
        "        new_s, r, terminated, truncated, info = env.step(a)\n",
        "\n",
        "        # record session history to train later\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        rewards.append(r)\n",
        "\n",
        "        s = new_s\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    return states, actions, rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkoQiea9C6Wt"
      },
      "outputs": [],
      "source": [
        "# test it\n",
        "states, actions, rewards = generate_session(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya-jRsPDC6Wt"
      },
      "source": [
        "### Computing cumulative rewards\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "G_t &= r_t + \\gamma r_{t + 1} + \\gamma^2 r_{t + 2} + \\ldots \\\\\n",
        "&= \\sum_{i = t}^T \\gamma^{i - t} r_i \\\\\n",
        "&= r_t + \\gamma * G_{t + 1}\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKFRyGtBC6Wt"
      },
      "outputs": [],
      "source": [
        "def get_cumulative_rewards(rewards,  # rewards at each step\n",
        "                           gamma=0.99  # discount for reward\n",
        "                           ):\n",
        "    \"\"\"\n",
        "    Take a list of immediate rewards r(s,a) for the whole session\n",
        "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
        "\n",
        "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
        "\n",
        "    A simple way to compute cumulative rewards is to iterate from the last\n",
        "    to the first timestep and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
        "\n",
        "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
        "    \"\"\"\n",
        "    G = []\n",
        "    for r in rewards[::-1]:\n",
        "       G.append(r + gamma * (G[-1] if len(G) > 0 else 0))\n",
        "    return np.array(G[::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihS3A_60C6Wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17deda15-4a38-4cb9-d3e5-c7998e8cfc0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looks good!\n"
          ]
        }
      ],
      "source": [
        "get_cumulative_rewards(rewards)\n",
        "assert len(get_cumulative_rewards(list(range(100)))) == 100\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n",
        "    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n",
        "    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n",
        "    [0, 0, 1, 2, 3, 4, 0])\n",
        "print(\"looks good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjgR181iC6Wu"
      },
      "source": [
        "#### Loss function and updates\n",
        "\n",
        "We now need to define objective and update over policy gradient.\n",
        "\n",
        "Our objective function is\n",
        "\n",
        "$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n",
        "\n",
        "REINFORCE defines a way to compute the gradient of the expected reward with respect to policy parameters. The formula is as follows:\n",
        "\n",
        "$$ \\nabla_\\theta \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\nabla_\\theta \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "We can abuse PyTorch's capabilities for automatic differentiation by defining our objective function as follows:\n",
        "\n",
        "$$ \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "When you compute the gradient of that function with respect to network weights $\\theta$, it will become exactly the policy gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5b0T8SFC6Wu"
      },
      "outputs": [],
      "source": [
        "# Your code: define optimizers\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "\n",
        "\n",
        "def train_on_session(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
        "    \"\"\"\n",
        "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
        "    Updates agent's weights by following the policy gradient above.\n",
        "    Please use Adam optimizer with default parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # cast everything into torch tensors\n",
        "    states = torch.tensor(states, dtype=torch.float32)\n",
        "    actions = torch.tensor(actions, dtype=torch.int64)\n",
        "    cumulative_returns = np.array(get_cumulative_rewards(rewards, gamma))\n",
        "    cumulative_returns = torch.tensor(cumulative_returns, dtype=torch.float32)\n",
        "\n",
        "    # predict logits, probas and log-probas using an agent.\n",
        "    logits = model(states)\n",
        "    probs = nn.functional.softmax(logits, -1)\n",
        "    log_probs = nn.functional.log_softmax(logits, -1)\n",
        "\n",
        "    assert all(isinstance(v, torch.Tensor) for v in [logits, probs, log_probs]), \\\n",
        "        \"please use compute using torch tensors and don't use predict_probs function\"\n",
        "\n",
        "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
        "    log_probs_for_actions = torch.sum(\n",
        "        log_probs * F.one_hot(actions, env.action_space.n), dim=1)\n",
        "\n",
        "    # Compute loss here. Don't forgen entropy regularization with `entropy_coef`\n",
        "    entropy = entropy_coef * torch.sum(probs * log_probs, dim=1).mean()\n",
        "    loss = - torch.mean(log_probs_for_actions * cumulative_returns) - entropy\n",
        "\n",
        "    # Gradient descent step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # technical: return session rewards to print them later\n",
        "    return np.sum(rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xergfeB6C6Wu"
      },
      "source": [
        "### The actual training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKUcUtRKC6Wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17765ac9-5b79-4703-9650-6b616d0ba714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mean reward: 9.250: 100%|██████████| 100/100 [00:44<00:00,  2.26it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "pbar = tqdm(range(100))\n",
        "for i in pbar:\n",
        "    rewards = [train_on_session(*generate_session(env)) for _ in range(100)]  # generate new sessions\n",
        "    res = np.mean(rewards)\n",
        "    pbar.set_description(f\"mean reward: {res:.3f}\")\n",
        "\n",
        "    if res > 500:\n",
        "        print(\"You Win!\")  # but you can train even further\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR2voSRdC6Wu"
      },
      "source": [
        "### Results & video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e96mgPOC6Wu"
      },
      "outputs": [],
      "source": [
        "# Record sessions\n",
        "\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "with gym.make(\"CartPole-v1\", render_mode=\"rgb_array\") as env, RecordVideo(\n",
        "    env=env, video_folder=\"./videos\"\n",
        ") as env_monitor:\n",
        "    sessions = [generate_session(env_monitor) for _ in range(10)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JEZ_hJHC6Wu"
      },
      "outputs": [],
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "video_path = video_paths[-1]  # You can also try other indices\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://stackoverflow.com/a/57378660/1214547\n",
        "    with video_path.open('rb') as fp:\n",
        "        mp4 = fp.read()\n",
        "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "else:\n",
        "    data_url = str(video_path)\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(data_url))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}