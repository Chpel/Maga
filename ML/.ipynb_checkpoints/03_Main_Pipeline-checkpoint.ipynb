{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"id\": list(range(1, 8)),\n",
    "    \"score\": [0.5, 0.1, 0.2, 0.6, 0.2, 0.3, 0.0], # так обычно выглядит выход из бинарного классификатора\n",
    "    \"class\": [0, 0, 0, 1, 1, 1, 0] # \"правильные\" метки\n",
    "})\n",
    "\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А как понять, насколько хороши эти предсказания?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP, TN, FP, FN, confusion matrix\n",
    "\n",
    "В бинарной классификации для каждого наблюдаемого бывает всего 4 ситуации, для каждой из (по историческим причинам) есть свои названия.\n",
    "\n",
    "True Positive - предсказано 1, метка -- 1\n",
    "\n",
    "True Negative - предсказано 0, метка -- 0\n",
    "\n",
    "False Positive - предсказано 1, метка -- 0\n",
    "\n",
    "False Negative - предсказано 0, метка -- 1\n",
    "\n",
    "### Задание: давайте вспомним, что такое accuracy, что такое точность (precision) и полнота (recall)\n",
    "\n",
    "**Accuracy** -- доля верно угаданных; то есть доля совпадающих значений в последних двух колонках\n",
    "\n",
    "**Recall** -- доля определённого первого класса среди истинного первого класса; то есть, сколько ИЗВЛЕКЛИ из нужного класса\n",
    "\n",
    "**Precision** -- доля правильных среди предсказанных как первый класс\n",
    "\n",
    "**F1-score** -- среднее гармоническое точности и полноты\n",
    "\n",
    "Как выразить эти метрики через TP, TN, FP, FN ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# это уже не только для бинарно классификации, можно построить confusion matrix для любого числа классов\n",
    "sns.heatmap(\n",
    "    confusion_matrix(df['score'] > 0.5, # а почему такой трешхолд?\n",
    "                     df['class']), \n",
    "    annot=True, \n",
    "    fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "df[\">2\"] = df[\"score\"].map(lambda x: 1 if x >= 0.2 else 0)\n",
    "df#.drop(\"score\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 3 / 5\n",
    "assert precision == precision_score(df[\"class\"], df[\">2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = 3 / 3\n",
    "assert recall == recall_score(df[\"class\"], df[\">2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 5 / 7 == accuracy_score(df[\"class\"], df[\">2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2* precision * recall / (precision + recall)\n",
    "assert f1 == f1_score(df[\"class\"], df[\">2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC [Reciever Operating Characteristic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(df[\"class\"], df[\"score\"])\n",
    "roc_auc = roc_auc_score(df[\"class\"], df[\"score\"])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "lw = 4 # line width\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC example by A. D.')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in list(thresholds):\n",
    "    TP = df[(df[\"score\"] >= t) & (df['class'] == 1)]['id'].count()\n",
    "    TN = df[(df[\"score\"] < t) & (df['class'] == 0)]['id'].count()\n",
    "    FP = df[(df[\"score\"] >= t) & (df['class'] == 0)]['id'].count()\n",
    "    FN = df[(df[\"score\"] < t) & (df['class'] == 1)]['id'].count()\n",
    "    TP_rate = TP / (TP + FN)\n",
    "    FP_rate = FP / (TN + FP)\n",
    "    print(f\" Threshold: {t} TP Rate: {TP_rate:6f} FP Rate: {FP_rate}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr, fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но вообще есть `plot_roc_curve` и вот такое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall curve\n",
    "\n",
    "Примерно такой же интерфейс. Кривая точность-полнота может быть довольно-таки бесноватой по сравнению с ROC curve; частый случай -- \"зубцы\", сейчас мы в этом убедимся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(df[\"class\"], df[\"score\"])\n",
    "\n",
    "precision, recall, thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть и более прогрессивные способы сделать красиво"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "pr_display = PrecisionRecallDisplay(precision=precision, recall=recall).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение. Реализуйте сами график precision-recall кривой и посчитайте площадь под ней"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# И ещё раз, без спешки\n",
    "\n",
    "Самое крупное кораблекрушение Европы в мирное время, в предполагаемых причинах которого до сих пор нет окончательной уверенности.\n",
    "\n",
    "```\n",
    "«Estonia» (ранее «Viking Sally», «Silja Star», «Wasa King») — \n",
    "эстонский паром судоходной компании «Estline», построенный \n",
    "в 1979 году в ФРГ на судоверфи «Meyer Werft» в Папенбурге. \n",
    "Затонул в Балтийском море в ночь с 27 на 28 сентября 1994 года, \n",
    "в результате крушения пропали без вести 757 человек и \n",
    "погибли 95 человек (всего 852) из 989 находившихся \n",
    "на борту пассажиров и членов экипажа. Это крупнейшее \n",
    "в Европе кораблекрушение в мирное время. \n",
    "```\n",
    "\n",
    "Датасет можно скачать [тут](https://www.kaggle.com/datasets/christianlillelund/passenger-list-for-the-estonia-ferry-disaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_data = pd.read_csv(\"data/estonia-passenger-list.csv\")\n",
    "all_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymized_data = all_data.drop([\"Firstname\", \"Lastname\", \"PassengerId\"], axis=1)\n",
    "anonymized_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = anonymized_data[\"Survived\"]\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymized_data[anonymized_data['Country'] == 'Belarus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ставим при необходимости библиотеку прямо из ноутбука"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# нарисуем среднюю выживаемость и дисперсию\n",
    "sns.barplot(x='Country',y='Survived', data=anonymized_data)\n",
    "\n",
    "# Поворот  подписей\n",
    "plt.xticks(rotation=70)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зависит ли выживаемость от категории Пассажиры/Passengers; Команда/Сrew \n",
    "sns.barplot(x='Category', y='Survived', data=anonymized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymized_data[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А как распределён возраст?\n",
    "\n",
    "Можно посмотреть встроенными средствами pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymized_data[\"Age\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "\n",
    "#### Dummy-coding AKA One-Hot-Encoding\n",
    "\n",
    "Но чаще всё-таки удобнее кодировать средствами sklearn, увидим ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.get_dummies(anonymized_data[\"Country\"], prefix=\"c\")\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сами разобьём на обучающую и тестовую выборки -- до всех предобработок, это важно!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "data_train, data_test, y_train, y_test = train_test_split(\n",
    "                                                    anonymized_data.drop([\"Survived\"], axis=1), # X\n",
    "                                                    anonymized_data[\"Survived\"], # y\n",
    "                                                    test_size=0.3, # доля от всех записей\n",
    "                                                    random_state=1337, # зерно\n",
    "                                                    stratify=anonymized_data[\"Survived\"], # а это что?\n",
    "                                        )\n",
    "\n",
    "# print(data_train.shape, y_train.shape, data_test.shape, y_test.shape)\n",
    "\n",
    "# np.sum(y_train) / y_train.shape[0], np.sum(y_test) / y_test.shape[0]\n",
    "# nonames_data.shape, data_train.shape\n",
    "# y_train, y_test\n",
    "# y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import sparse as sp\n",
    "\n",
    "# Не все классификаторы умеют обращаться с категориальными признаками. \n",
    "def prepare_features_for_logreg(data: pd.DataFrame, cat_encoder=None, real_scaler=None):\n",
    "    cat_columns = [\"Country\", \"Sex\", \"Category\"]  \n",
    "    real_columns = [\"Age\"]\n",
    "    \n",
    "    # categorical features\n",
    "    if cat_encoder is None:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        ohe.fit(data[cat_columns])\n",
    "    else:\n",
    "        ohe = cat_encoder\n",
    "    X_cat = ohe.transform(data[cat_columns])\n",
    "    cat_fnames = ohe.get_feature_names_out(cat_columns)\n",
    "    \n",
    "    # real-valued features\n",
    "    if real_scaler is None:\n",
    "        stsc = StandardScaler()\n",
    "        stsc.fit(data[real_columns])\n",
    "    else:\n",
    "        stsc = real_scaler\n",
    "    X_real = stsc.transform(data[real_columns])\n",
    "    feature_matrix = sp.hstack([X_cat, X_real])\n",
    "    \n",
    "    return feature_matrix, list(cat_fnames) + real_columns, ohe, stsc\n",
    "\n",
    "X_train_sparse, fnames_sparse, encoder_sparse, scaler = prepare_features_for_logreg(data_train)\n",
    "X_test_sparse, _, _, _ = prepare_features_for_logreg(data_test, encoder_sparse, scaler)\n",
    "\n",
    "X_train_sparse.shape, X_test_sparse.shape\n",
    "# X_train_sparse.todense()\n",
    "# X_test_sparse.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_linear = LogisticRegression(C=0.99, class_weight=\"balanced\", \n",
    "                                solver=\"saga\", penalty=\"l1\")\n",
    "clf_linear.fit(X_train_sparse, y_train)\n",
    "\n",
    "y_pred = clf_linear.predict(X_test_sparse)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "# clf_linear.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.explain_weights(clf_linear, feature_names=fnames_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хороший способ проверить, не ерунду ли мы сделали: внимание на **accuracy** и на метрики в разделе **macro-averaged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf_dummy = DummyClassifier(strategy=\"most_frequent\").fit(X_train_sparse, y_train)\n",
    "y_pred = clf_dummy.predict(X_test_sparse)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим признаки для логических классификаторов -- там обычно можно без разреженных признаков и нормализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from scipy import sparse as sp\n",
    "\n",
    "def prepare_features_for_logic(data: pd.DataFrame, cat_encoder=None):\n",
    "    \n",
    "    cat_columns = [\"Country\", \"Sex\", \"Category\"]  \n",
    "    real_columns = [\"Age\"]\n",
    "    \n",
    "    # categorical features\n",
    "    \n",
    "    if cat_encoder is None:\n",
    "        oe = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "        oe.fit(data[cat_columns])\n",
    "    else:\n",
    "        oe = cat_encoder\n",
    "    \n",
    "    X_cat = oe.transform(data[cat_columns])\n",
    "    mapped_cat_values = oe.categories_\n",
    "    cat_fnames = cat_columns\n",
    "    \n",
    "    # real-valued features\n",
    "    \n",
    "    # todo: вообще очень часто есть смысл отбросить из обучающей выборки примеры, \n",
    "    #       значения которых редки (например, выпадающие далеко \"за три сигмы\")\n",
    "    \n",
    "    X_real = data[real_columns].values    \n",
    "    feature_matrix = np.hstack([X_cat, X_real]) # note: `np` for dense Numpy matrices\n",
    "    \n",
    "    return feature_matrix, list(cat_fnames) + real_columns, oe, mapped_cat_values\n",
    "\n",
    "X_train_dense, fnames_dense, encoder, mapped_cat_values = prepare_features_for_logic(data_train)\n",
    "X_test_dense, _, _, _ = prepare_features_for_logic(data_test, encoder)\n",
    "\n",
    "\n",
    "X_train_dense.shape, X_test_dense.shape\n",
    "\n",
    "mapped_cat_values\n",
    "# X_train_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=2, class_weight=\"balanced\").fit(X_train_dense, y_train)\n",
    "y_pred = clf.predict(X_test_dense)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но пока мы даже не попытались настроить модели, результаты ничего не значат.\n",
    "\n",
    "Кстати, смотрите, как можно.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(12, 8), dpi=80)\n",
    "\n",
    "\n",
    "plot_tree(clf, feature_names=fnames_dense, class_names=[\"Dead\", \"Surv\"], proportion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain Like I'm Five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.explain_weights(clf, feature_names=fnames_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Познакомились с minimum minimorum, поперебираем\n",
    "попробуем получить результаты получше со случайным лесом\n",
    "\n",
    "Посмотрим на самые важные параметры.\n",
    "\n",
    "```\n",
    "class sklearn.ensemble.RandomForestClassifier(\n",
    "\n",
    "                        n_estimators=100,  \n",
    "                            Число деревьев.              \n",
    "                            \n",
    "                        criterion='gini', \n",
    "                            Критерий: индекс Джини либо энтропия, может зависеть от вида дерева\n",
    "                            \n",
    "                        max_depth=None, \n",
    "                            Самая, пожалуй, естественная регуляризация -- ограничение глубины дерева\n",
    "                            \n",
    "                        min_samples_split=2,\n",
    "                            Сколько должно попасть в вершину объектов, чтобы её можно было ветвить дальше\n",
    "                            \n",
    "                        min_samples_leaf=1, \n",
    "                            Очень мощный и важный регуляризатор! Сколько минимум объектов должно быть в листе\n",
    "                            \n",
    "                        max_features='auto', \n",
    "                            Среди какого числа признаков выбираем очередное ветвление\n",
    "                            \n",
    "                        max_leaf_nodes=None, \n",
    "                            Хороший регуляризатор -- ограничение на количество листьев; добавляются по убыванию\n",
    "                            снижения impurity.\n",
    "                            \n",
    "                        min_impurity_decrease=0.0, \n",
    "                            Порог по уменьшению impurity, который запрещает ветвить дерево дальше.\n",
    "                        \n",
    "                        bootstrap=True, \n",
    "                            Если False, обучаем каждое дерево на всём наборе данных. \n",
    "                            Если True, только на части, размер которой задан в max_samples.\n",
    "                            \n",
    "                        n_jobs=None, \n",
    "                            На сколько job-ов распараллелить.\n",
    "                            \n",
    "                        random_state=None, \n",
    "                            Ну, тут всё понятно: случайный seed, позволяющий воспроизводить результаты.\n",
    "                        \n",
    "                        verbose=0, \n",
    "                            Степень подробности протоколирования хода обучения и всего такого. Обычно 0,1,2.\n",
    "                            \n",
    "                        warm_start=False, \n",
    "                            Это такая возможность переиспользовать обученный ансамбль для последующих задач.\n",
    "                             \n",
    "                        max_samples=None\n",
    "                            Сколько максимум сэмплов брать из датасета для обучения очередного дерева, если bootstrap\n",
    "                        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [10, 50, 100],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 5],\n",
    "    \"max_samples\": [0.3, None],\n",
    "    \"class_weight\" : [\"balanced\", \"balanced_subsample\"]\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape, type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение\n",
    "Зачем нужен KFold? Почему нельзя просто считать метрики на тесте?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=100, shuffle=True)\n",
    "\n",
    "print(y_train.values.mean())\n",
    "\n",
    "for array1, array2 in kfold.split(X_train_dense, y_train):   \n",
    "    x_train_cv = X_train_dense[array1]\n",
    "    y_train_cv = np.array(y_train)[list(array1)]\n",
    "    \n",
    "    x_test_cv = X_train_dense[array2]\n",
    "    y_test_cv = np.array(y_train)[list(array2)]\n",
    "    \n",
    "    print(y_train_cv.mean(), y_test_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "scores = [\"accuracy\"]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning for %s\" % score)\n",
    "    print()\n",
    "    # loo = LeaveOneOut()\n",
    "\n",
    "    clf = GridSearchCV(RandomForestClassifier(n_jobs=-1, random_state=100), \n",
    "                       param_grid, scoring=score, verbose=1, cv=3)\n",
    "\n",
    "    clf.fit(X_train_dense, y_train)\n",
    "\n",
    "    print(\"Best params on dev set:\")\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    print(\"Scores on development set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "    best_model = clf.best_estimator_\n",
    "    best_model.fit(X_train_dense, y_train)\n",
    "\n",
    "    y_true, y_pred = y_test, best_model.predict(X_test_dense)\n",
    "    \n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.explain_weights(best_model, feature_names=fnames_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Укладываем вообще всё в один пайплайн\n",
    "---\n",
    "Результаты вряд ли будут впечатляющими, но на этом примере посмотрим, как можно удобно запрограммировать перебор параметров не только классификации.\n",
    "\n",
    "Понизим размерность и применим KNN.\n",
    "\n",
    "Вариантов понижения размерности [много](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition). Возьмём самый стандартный и работающий с разреженными признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "decomposer = TruncatedSVD(n_components=6, random_state=10, n_iter=200)\n",
    "X_train_svd = decomposer.fit_transform(X_train_sparse)\n",
    "X_test_svd = decomposer.transform(X_test_sparse)\n",
    "\n",
    "X_train_svd.shape, X_test_svd.shape, X_train_sparse.shape, X_train_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[('svd', decomposer), \n",
    "                       ('knn', knn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        \"svd__n_components\": [2, 4, 6, 10],\n",
    "        \"svd__n_iter\": [5, 100, 1000],\n",
    "        \"knn__n_neighbors\": [1, 2, 3, 4, 5],\n",
    "        \"knn__weights\" : [\"uniform\", \"distance\"],\n",
    "        \"knn__metric\" : [\"euclidean\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scores = [\"f1_macro\"]#, \"accuracy\"]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(pipe, param_grid, scoring=score, verbose=2, cv=3)\n",
    "    clf.fit(X_train_sparse, y_train)\n",
    "\n",
    "    print(\"Best params on dev set:\")\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    print(\"Scores on development set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "    best_model = clf.best_estimator_\n",
    "    best_model.fit(X_train_sparse, y_train)\n",
    "\n",
    "    y_true, y_pred = y_test, best_model.predict(X_test_sparse)\n",
    "    \n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание со звездочкой 1\n",
    "\n",
    "Получите accuracy > 0.89 на тестовом датасете. Можно пользоваться любым классификатором **из sklearn**. Ансамблями пользоваться можно.\n",
    "\n",
    "### XtreemeGradientBoosting и нейронные сети запрещены. \n",
    "\n",
    "Выполняйте это задание в отдельном ноутбуке. Если у Вас получилось набрать нужный accuracy, то можете прислать его мне на проверку. Критeрии того, чтобы я его начал смотреть:\n",
    "\n",
    "* Ваш код читаем и прокоментирован, нет серьезных противоречий PEP8\n",
    "* Ваш ноутбук запускается и нигде не падает по кнопке \"Run all\". \n",
    "* В последней ячейке Вашего кода есть classification_report с accuracy > 0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание со звездочкой 2\n",
    "\n",
    "Допустим, у вас есть два множества **A** и **B** точек на плоскости. Линейная регрессия на плоскости -- это \n",
    "просто прямая, ее можно представить как функцию $ y = ax + b$.\n",
    "\n",
    "Линейная регрессия, обученная на множестве **А**, имеет коэффициент **$a > 0$**. То же самое верно и для линейной регрессии, обученной на множестве **B**. Правда ли, что если обучить линейную регрессию на множестве $A \\cup B$, то у полученной прямой коэффициент **a** будет больше 0?\n",
    "\n",
    "Если да, докажите. Если нет -- пришлите мне контрпример (jupyter notebook, в котором есть эти множества и линейные регрессии). Требования к ноутбуку можно найти в задаче выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
