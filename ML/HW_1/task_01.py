# coding: utf-8
"""
    Задание: ближайшие соседи, синтетический датасет, Евклидово расстояние.

    В задании требуется реализовать метод ближайших соседей для двух классов
    с параметризуемым числом соседей, метрику accuracy и еще одну метрику
    на ваш выборю.

    Критерии оценивания: 
        Всего можно получить 10 баллов, Ваша оценка равна числу полученных баллов.
        *   За KNN -- максимум 4 балла. 3 балла вы получаете, если ваш код работает
            (проходит соотвествующий assert), четвертый -- за реализацию с использованием
            внутренних функций numpy. Еще можно получить бонусный балл, см. комментарии к
            методу fit. Он не входит в эти 10 баллов, приравнивается к задаче со звездочкой
            и будет учитываться как-то по-особенному.

        *   За accuracy и какую-то еще метрику -- по 1 баллу каждая, ставятся за прохождение assert'ов.

        *   За картинки в matplotlib: 1 балл за каждую картинку, если картинка читаема 
            (точки не сильно налазят друг на друга, надписи читаемы, есть название графика, 
            легенда, оси и все такое). 0.5 балла, если там хотя-бы нарисовано то, что нужно.

        *   СЕРЬЕЗНОЕ несоотвествие PEP8 -- -1 балл.

    Рекомендую начинать разбираться с кодом -- после if __name__ == "__main__",
    а потом уже переходить к accuracy и классу KNN. 
"""
import numpy as np
from typing import SupportsIndex
from sklearn.metrics import classification_report, accuracy_score


class KNN(object):
    """
        Класс с реализацией метода ближайших соседей.
    """

    def __init__(self, n_neighbours: int = 4):
        # обучающая выборка: признаки
        self.X_train = None

        # обучающая выборка: метки классов
        self.y_train = None

        # число ближайших соседей
        self.n_neighbours = n_neighbours

    def fit(self, X: np.ndarray, y: SupportsIndex):
        """
            В методе fit (по аналогии с API sklearn) происходит обучение модели.
            Здесь как такового обучения у нас нет, надо просто запомнить датасет
            как "состояние объекта" KNN.
        """
        # todo: Запомнить обучающую выборку в атрибуты объекта self.X_train и self.y_train.

        # todo: (нам и так пойдёт, но вообще в прикладных реализациях используется многомерное
        # todo: индексирование и всякие приёмы, которые экономят память, позволяя не запоминать
        # todo: весь датасет, как это делаем мы. Если вы реализуете здесь что-то, что я посчитаю
        # todo: интересным, получите бонусный балл :) )
        # ???
        pass

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
            В методе predict (по аналогии с API sklearn) происходит вычисление предсказанны значений.
        """

        # todo: 1) Вычислить евклидово расстояние между всеми парами точек вида:
        # todo:    одна из X, другая из self.X_train. Для удобства лучше записать расстояния в матрицу.

        # todo: 2) Для каждой точки из X найти self.n_neighbours ближайших из self.X_train.
        # todo:    В этом поможет метод np.argsort с правильным параметром axis.
        # todo:    Выберите среди них самую частотную соседскую метку (из self.y_train).
        # todo:    А именно -- если количество меток "1" среди голосов >= 50%, назначаем её.

        # todo: Рекомендую интересующимся разобраться, как всё это эффективно
        # todo: делается с помощью broadcasting (о котором я рассказывал очень поверхностно).
        # todo: Ключевые слова: np.newaxis, np.square, np.sum, np.sqrt, np.argsort

        # Упражнение. Какова ассимптотическая сложность этой функции? Как она зависит от
        # размерности пространства?

        # Сделано эффективно, с помощью векторных операций: 4 балла, сделано как-то: 3 балла.
        return np.ones(X.shape[0])


def accuracy(labels_true: np.ndarray, labels_predicted: np.ndarray) -> float:
    """
        Доля верно предсказанных меток; это ценная, но далеко не лучшая (помните, почему?)
        оценка качества классификации, но давайте её реализуем
    :param labels_true: одномерный массив int-ов, истинные метки
    :param labels_predicted: одномерный массив int-ов, предсказанные метки
    :return: число совпавших меток делим на общее число меток
    """
    return 0.0

def metric(labels_true: np.ndarray, labels_predicted: np.ndarray) -> float:
    """
        Реализуйте какую-нибудь другую метрику качества классификации. Можно
        взять из тех, что были на практике, можно принести какую-то свою.
    :param labels_true: одномерный массив int-ов, истинные метки
    :param labels_predicted: одномерный массив int-ов, предсказанные метки
    :return: число совпавших меток делим на общее число меток
    """
    return 0.0


if __name__ == "__main__":
    import matplotlib.pyplot as plt

    # фиксируем random seed для воспроизводимости результата
    np.random.seed(100)

    # создаём синтетический набор данных для обучения и тестирования
    means0 = [1, -1]
    covs0 = [[7, 3],
             [3, 7]]
    x0, y0 = np.random.multivariate_normal(means0, covs0, 190).T

    means1 = [0, -4]
    covs1 = [[0.1, 0.0],
             [0.0, 25]]
    x1, y1 = np.random.multivariate_normal(means1, covs1, 100).T

    # можете раскомментировать и посмотреть, как выглядят данные
    # plt.plot(x0, y0, marker='o', color='b', ls='')
    # plt.plot(x1, y1, marker='o', color='r', ls='')
    # plt.show()

    # если непонятно, что здесь происходит, распечатайте массивы,
    # а лучше .shape каждого из них
    data0 = np.vstack([x0, y0]).T
    labels0 = np.zeros(data0.shape[0])

    data1 = np.vstack([x1, y1]).T
    labels1 = np.ones(data1.shape[0])

    data = np.vstack([data0, data1])
    labels = np.hstack([labels0, labels1])
    total_size = data.shape[0]
    print("Original dataset shapes:", data.shape, labels.shape)

    # берём случайные 70% как train
    train_size = int(total_size * 0.7)
    indices = np.random.permutation(total_size)

    # обратите внимание на возможность объявлять несколько переменных в одной строке,
    # бывает удобно, особенно когда переменные связаны по смыслу и когда в правой части короткие выражения
    X_train, y_train = data[indices][:train_size], labels[indices][:train_size]
    X_test, y_test = ...
    print("Train/test sets shapes:", X_train.shape, X_test.shape)

    # todo: циклом for переберите здесь значения числа ближайших соседей от 1 до 5

    # создаём объект-классификатор
    predictor = KNN(n_neighbours=3)

    # выбор гиперпараметров (здесь это n_neighbours) так, чтобы модель не переобучилась, --
    # отдельная история; в этом задании нас это волновать не будет
    predictor.fit(X_train, y_train)
    y_pred = predictor.predict(X_test)

    # Вычислите точность ваших предсказаний.
    print("Accuracy: %.4f [ours]" % accuracy(y_test, y_pred))
    assert abs(accuracy_score(y_test, y_pred) - accuracy(y_test, y_pred)) < 1e-5,\
        "Implemented accuracy is not the same as sci-kit learn one!"
    
    # Проверьте качество вашего классификатора.
    assert accuracy_score(y_test, y_pred) > 19. / 29.\
        "Your classifier is worse than the constant !"

    # Вычислите какую-то другую метрику (на ваш выбор), сравните с библиотечной версией
    print("Accuracy: %.4f [ours]" % accuracy(y_test, y_pred))
    assert abs(metric(y_test, y_pred) - ...) < 1e-5,\
        "Implemented metric is not the same as sci-kit learn one!"

    # удобный инструмент из sklearn, который посчитает некоторые другие стандартные метрики за вас
    print(classification_report(y_test, y_pred))

    #   Разберитесь с интерфейсом matplotlib (начать можно с моих примеров, но погуглить придётся)
    #   и подготовьте ТРИ картинки по ТЕСТОВОЙ ВЫБОРКЕ: исходные метки, метки с n_neighbours = 1
    #   и лучшим n_neighbours в рассмотренном нами интервале. Один класс -- одним цветом, другой другим
    #   (например, синий и красный). 

    #   Также на каждой из трёх картинок должны быть точки из ОБУЧАЮЩЕЙ ВЫБОРКИ, раскр. в соответствующие цвета
    #   (но они не должны "перекрывать" тестовые -- можно сделать их полупрозрачными, можно маленькими
    #   точками/крестиками -- придумайте сами; постарайтесь сделать результат читаемым и анализируемым).
    #   Сохраните картинки на диск (matplotlib savefig). 
    #   Красивые (читаемые) картинки -- 2 балла, плохие картинки (но на которых нарисованы правильные вещи) -- 1 балл

    #   ЧЕТВЕРТАЯ кактинка -- график зависимости метрик от числа соседей. Две метрики на одном графике, разным
    #   цветом, не забываем про легенду. Если у метрик разные масштабы -- две вертикальных оси. (погуглите!)
