{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0701a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ddbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle --upgrade\n",
    "#!kaggle competitions download -c animal-shelter-logs\n",
    "#!unzip animal-shelter-logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7546e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Socks</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Cat</td>\n",
       "      <td>2 months</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Black/White</td>\n",
       "      <td>2014-06-11 14:36:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vera</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>Cat</td>\n",
       "      <td>1 month</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Tortie/White</td>\n",
       "      <td>2014-07-18 08:10:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biscuit</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Dog</td>\n",
       "      <td>3 months</td>\n",
       "      <td>Chihuahua Shorthair Mix</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2016-01-02 17:28:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kitten</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>Cat</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Calico</td>\n",
       "      <td>2014-02-19 17:27:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Cat</td>\n",
       "      <td>2 months</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Orange Tabby</td>\n",
       "      <td>2014-07-21 17:34:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18705</th>\n",
       "      <td>Maverick</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Dog</td>\n",
       "      <td>7 months</td>\n",
       "      <td>Labrador Retriever Mix</td>\n",
       "      <td>Chocolate/White</td>\n",
       "      <td>2015-04-14 18:35:00</td>\n",
       "      <td>1</td>\n",
       "      <td>18705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18706</th>\n",
       "      <td>Thor</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>Dog</td>\n",
       "      <td>3 months</td>\n",
       "      <td>Pit Bull/Chihuahua Shorthair</td>\n",
       "      <td>Tan</td>\n",
       "      <td>2013-10-28 12:33:00</td>\n",
       "      <td>2</td>\n",
       "      <td>18706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18707</th>\n",
       "      <td>Roxy</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>Dog</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "      <td>White/Brown Brindle</td>\n",
       "      <td>2014-12-05 15:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>18707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18708</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>Dog</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Newfoundland Mix</td>\n",
       "      <td>Black</td>\n",
       "      <td>2014-06-29 17:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>18708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18709</th>\n",
       "      <td>Lotus</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>Cat</td>\n",
       "      <td>2 months</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Black</td>\n",
       "      <td>2013-12-24 16:42:00</td>\n",
       "      <td>0</td>\n",
       "      <td>18709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18710 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name SexuponOutcome AnimalType AgeuponOutcome  \\\n",
       "0         Socks  Neutered Male        Cat       2 months   \n",
       "1          Vera  Intact Female        Cat        1 month   \n",
       "2       Biscuit  Neutered Male        Dog       3 months   \n",
       "3        Kitten  Spayed Female        Cat        2 years   \n",
       "4           NaN  Neutered Male        Cat       2 months   \n",
       "...         ...            ...        ...            ...   \n",
       "18705  Maverick  Neutered Male        Dog       7 months   \n",
       "18706      Thor    Intact Male        Dog       3 months   \n",
       "18707      Roxy  Spayed Female        Dog        2 years   \n",
       "18708       NaN    Intact Male        Dog        2 years   \n",
       "18709     Lotus  Intact Female        Cat       2 months   \n",
       "\n",
       "                              Breed                Color             DateTime  \\\n",
       "0            Domestic Shorthair Mix          Black/White  2014-06-11 14:36:00   \n",
       "1            Domestic Shorthair Mix         Tortie/White  2014-07-18 08:10:00   \n",
       "2           Chihuahua Shorthair Mix               Yellow  2016-01-02 17:28:00   \n",
       "3            Domestic Shorthair Mix               Calico  2014-02-19 17:27:00   \n",
       "4            Domestic Shorthair Mix         Orange Tabby  2014-07-21 17:34:00   \n",
       "...                             ...                  ...                  ...   \n",
       "18705        Labrador Retriever Mix      Chocolate/White  2015-04-14 18:35:00   \n",
       "18706  Pit Bull/Chihuahua Shorthair                  Tan  2013-10-28 12:33:00   \n",
       "18707                  Pit Bull Mix  White/Brown Brindle  2014-12-05 15:14:00   \n",
       "18708              Newfoundland Mix                Black  2014-06-29 17:08:00   \n",
       "18709        Domestic Shorthair Mix                Black  2013-12-24 16:42:00   \n",
       "\n",
       "       Outcome     ID  \n",
       "0            0      0  \n",
       "1            3      1  \n",
       "2            2      2  \n",
       "3            0      3  \n",
       "4            0      4  \n",
       "...        ...    ...  \n",
       "18705        1  18705  \n",
       "18706        2  18706  \n",
       "18707        0  18707  \n",
       "18708        1  18708  \n",
       "18709        0  18709  \n",
       "\n",
       "[18710 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe7d27",
   "metadata": {},
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5892a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SexPreproc(df: pd.Series, model=None):\n",
    "    df.fillna('Unknown', inplace=True)\n",
    "    res = pd.DataFrame()\n",
    "    res['Gender'] = df.apply(lambda x: x.split()[-1])\n",
    "    res['Status'] = df.apply(lambda x: x.split()[0])\n",
    "    res.loc[res['Status']=='Neutered','Status'] = 'Spayed'\n",
    "    if model == None:\n",
    "        model = OneHotEncoder(drop=['Unknown', 'Unknown'])\n",
    "        model.fit(res)\n",
    "    return pd.DataFrame(model.transform(res).toarray(), columns=model.get_feature_names_out()), model\n",
    "\n",
    "def AnimalPreproc(df: pd.Series, model=None):\n",
    "    res = np.array(df).reshape(-1,1)\n",
    "    if model==None:\n",
    "        model = LabelBinarizer()\n",
    "        model.fit(df)\n",
    "    return pd.DataFrame(data=model.transform(res), columns=['cat/dog']), model\n",
    "\n",
    "def AgePreproc(df: pd.Series, filler=None):\n",
    "    df.fillna('-1 days', inplace=True)\n",
    "    res = pd.DataFrame()\n",
    "    res['date_num'] = df.apply(lambda x: int(x.split()[0]))\n",
    "    res['date_type'] = df.apply(lambda x: x.split()[1].rstrip('s'))\n",
    "    df_period = res['date_num'] * res['date_type'].map({'month' : 30, 'year': 365, 'week': 7, 'day': 1})\n",
    "    if filler == None:\n",
    "        filler = df_period[df_period > 0].mean()\n",
    "    df_period[df_period <= 0] = filler\n",
    "    df_period.name = 'period'\n",
    "    return np.log(df_period), filler\n",
    "\n",
    "def BreedPreproc(df: pd.Series, model=None, best=None):\n",
    "    clear = model==None\n",
    "    df = df.apply(lambda x: x.lower()\\\n",
    "             .replace('dog', ' dog')\\\n",
    "             .replace('hound', ' hound')\\\n",
    "             .replace('mastiff', ' mastiff')\\\n",
    "             .replace('dogo', 'dog')\\\n",
    "             .replace('dogue', 'dog')\\\n",
    "             .replace('greater', 'great')\\\n",
    "             .replace('pbgv', 'petit basset griffon venden')\n",
    "             .replace('italiano', 'italian')\\\n",
    "             .replace('havana', 'havanese')\\\n",
    "             .replace('bay retr', 'bay retriever')\\\n",
    "             .replace('terrier', 'terr')\n",
    "             .replace('haired', ' hair')\\\n",
    "             .replace('hair', ' hair')\\\n",
    "             .replace('spaniel', 'span')\\\n",
    "             .replace('pinscher', ' pinsch')\\\n",
    "             .replace('pointing', 'pointer')\\\n",
    "             .replace('akita', 'akita inu')\\\n",
    "             .replace('imaal', 'imaal terr'))\n",
    "    k_breeds = np.array(df.apply(lambda x: x.count('/')) + 1)\n",
    "    if clear:\n",
    "        model = CountVectorizer(stop_words=['de', 'st', 'of'])\n",
    "        model.fit(df)\n",
    "    res = pd.DataFrame(data=model.transform(df).toarray() / k_breeds.reshape(-1,1), columns=list(model.get_feature_names_out()))\n",
    "    if clear:\n",
    "        best = res.sum().sort_values(ascending=False)[:150].index\n",
    "    return res, model, best\n",
    "\n",
    "def ColorPreproc(df: pd.Series, model=None):\n",
    "    if model==None:\n",
    "        model = CountVectorizer()\n",
    "        model.fit(df)\n",
    "    k_colors = np.array(df.apply(lambda x: x.count('/')) + 1)\n",
    "    res = pd.DataFrame(data=model.transform(df).toarray() / k_colors.reshape(-1,1), columns=list(model.get_feature_names_out()))\n",
    "    return res, model\n",
    "\n",
    "def DatePreproc(df: pd.Series):\n",
    "    df_d = pd.to_numeric(pd.to_datetime(df))\n",
    "    return df_d\n",
    "\n",
    "def ReScale(df: pd.DataFrame, scaler=None):\n",
    "    if scaler == None:\n",
    "        scaler=StandardScaler()\n",
    "    df_res = scaler.fit_transform(df)\n",
    "    return df_res, scaler\n",
    "\n",
    "def preprocessing(df: pd.DataFrame, models=None):\n",
    "    if models == None:\n",
    "        models = {'gender' : None, 'Animal': None,\n",
    "                  'Age': None,'Breed': None, 'Best': None,\n",
    "                  'Color': None,'Scaler': None}\n",
    "    #обработка каждого столбца\n",
    "    df_gen_bin, models['gender'] = SexPreproc(df['SexuponOutcome'], models['gender'])\n",
    "    df_at, models['Animal'] = AnimalPreproc(df['AnimalType'], models['Animal'])\n",
    "    df_period, models['Age'] = AgePreproc(df['AgeuponOutcome'], models['Age'])\n",
    "    df_b, models['Breed'], models['Best'] = BreedPreproc(df['Breed'], models['Breed'], models['Best'])\n",
    "    df_c, models['Color'] = ColorPreproc(df['Color'], models['Color'])\n",
    "    df_d = DatePreproc(df['DateTime'])\n",
    "    #объединение результатов предобработки по каждому столбцу\n",
    "    #\n",
    "    X = df_gen_bin.merge(df_at, left_index=True, right_index=True)\\\n",
    "    .merge(df_period, left_index=True, right_index=True)\\\n",
    "    .merge(df_b, left_index=True, right_index=True)\\\n",
    "    .merge(df_c, left_index=True, right_index=True)\\\n",
    "    .merge(df_d, left_index=True, right_index=True)\n",
    "    #шкалирование\n",
    "    X[['period', 'DateTime']], models['Scaler'] = ReScale(X[['period', 'DateTime']], models['Scaler'])\n",
    "    y=None\n",
    "    if 'Outcome' in df.columns:\n",
    "        y = df.Outcome\n",
    "        #up-sample\n",
    "        X = pd.concat([X, *([X[y==2]] * 1), *([X[y==3]] * 5), *([X[y==4]] * 50)], ignore_index=True)\n",
    "        y = pd.concat([y, *([y[y==2]] * 1), *([y[y==3]] * 5), *([y[y==4]] * 50)], ignore_index=True)\n",
    "    return X,y,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad3b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,models = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7d55928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34405, 270)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72ab8ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['abyssinian', 'affen', 'airedale', 'akita', 'alaskan', 'american',\n",
       "        'anatol', 'angora', 'apso', 'argentino', 'australian', 'balinese',\n",
       "        'basenji', 'basset', 'bay', 'beagle', 'beauceron', 'bedlington',\n",
       "        'belgian', 'bengal', 'bernard', 'bernese', 'bichon', 'black_x', 'blood',\n",
       "        'blue_x', 'bluetick', 'bobtail', 'boerboel', 'bombay', 'bordeaux',\n",
       "        'border', 'boston', 'boxer', 'boykin', 'brindle_x', 'british',\n",
       "        'brittany', 'brown_x', 'bruss', 'bull', 'burmese', 'cairn', 'canaan',\n",
       "        'canario', 'cane', 'cardigan', 'carolina', 'catahoula', 'cattle',\n",
       "        'cavalier', 'chesa', 'chihuahua', 'chin', 'chinese', 'chow', 'coat',\n",
       "        'coated', 'cocker', 'collie', 'coon', 'corgi', 'cornish', 'corso',\n",
       "        'crested', 'cur', 'dachshund', 'dalmatian', 'dane', 'devon', 'doberman',\n",
       "        'dog', 'domestic', 'duck', 'dutch', 'english', 'eskimo', 'feist',\n",
       "        'field', 'finnish', 'flat', 'fox', 'french', 'frise', 'german', 'giant',\n",
       "        'glen', 'golden', 'great', 'grey', 'griffon', 'hair', 'harrier',\n",
       "        'havanese'],\n",
       "       dtype='object'),\n",
       " Index(['heeler', 'highland', 'himalayan', 'hound', 'husky', 'ibizan', 'imaal',\n",
       "        'inu', 'irish', 'italian', 'jack', 'japanese', 'jindo', 'keeshond',\n",
       "        'kelpie', 'kuvasz', 'labrador', 'lacy', 'landseer', 'leonberger',\n",
       "        'lhasa', 'long', 'lowchen', 'maine', 'malamute', 'malinois', 'maltese',\n",
       "        'manchester', 'manx', 'mastiff', 'medium', 'miniature', 'mix',\n",
       "        'mountain', 'mouth', 'neapolitan', 'newfoundland', 'norfolk', 'norwich',\n",
       "        'nova', 'ocicat', 'old', 'otter', 'papillon', 'parson', 'patterdale',\n",
       "        'pekingese', 'pembroke', 'pequeno', 'persian', 'petit', 'pharaoh',\n",
       "        'picardy', 'pinsch', 'pit', 'pixiebob', 'plott', 'podengo', 'pointer',\n",
       "        'pomeranian', 'poodle', 'presa', 'pug', 'pyrenees', 'queensland',\n",
       "        'ragdoll', 'rat', 'redbone', 'retriever', 'rex', 'rhod', 'ridgeback',\n",
       "        'rottweiler', 'rough', 'russell', 'russian', 'saluki', 'samoyed',\n",
       "        'schipperke', 'schnauzer', 'scotia', 'scottish', 'setter', 'sharpei',\n",
       "        'sheep', 'shepherd', 'shetland', 'shiba', 'shih', 'short', 'siamese',\n",
       "        'siberian', 'silky', 'skye', 'smooth', 'snowshoe', 'soft', 'span',\n",
       "        'spanish', 'sphynx'],\n",
       "       dtype='object'),\n",
       " Index(['spinone', 'spitz', 'springer', 'staffordshire', 'standard', 'swedish',\n",
       "        'swiss', 'tan_x', 'tennesse', 'terr', 'tervuren', 'tibetan', 'tolling',\n",
       "        'tonkinese', 'toy', 'treeing', 'turkish', 'tzu', 'unknown', 'vallhund',\n",
       "        'van', 'venden', 'vizsla', 'walker', 'water', 'weimaraner', 'welsh',\n",
       "        'west', 'wheaten', 'whippet', 'wire', 'wolf', 'yorkshire', 'agouti',\n",
       "        'apricot', 'black_y', 'blue_y'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[6:100], X.columns[100:200], X.columns[200:237]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f86176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Status_Intact</th>\n",
       "      <th>Status_Spayed</th>\n",
       "      <th>cat/dog</th>\n",
       "      <th>period</th>\n",
       "      <th>abyssinian</th>\n",
       "      <th>affen</th>\n",
       "      <th>airedale</th>\n",
       "      <th>akita</th>\n",
       "      <th>...</th>\n",
       "      <th>tabby</th>\n",
       "      <th>tan_y</th>\n",
       "      <th>tick</th>\n",
       "      <th>tiger</th>\n",
       "      <th>torbie</th>\n",
       "      <th>tortie</th>\n",
       "      <th>tricolor</th>\n",
       "      <th>white</th>\n",
       "      <th>yellow</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.578521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.701037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.507999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.945517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.527575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.131035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.945517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.788962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8014</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.109633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8015</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.468008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.201495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.578521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.391051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.308984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8019 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender_Female  Gender_Male  Status_Intact  Status_Spayed  cat/dog  \\\n",
       "0               1.0          0.0            1.0            0.0        0   \n",
       "1               1.0          0.0            0.0            1.0        0   \n",
       "2               0.0          1.0            0.0            1.0        0   \n",
       "3               0.0          1.0            0.0            1.0        0   \n",
       "4               1.0          0.0            0.0            1.0        0   \n",
       "...             ...          ...            ...            ...      ...   \n",
       "8014            1.0          0.0            0.0            1.0        1   \n",
       "8015            1.0          0.0            1.0            0.0        1   \n",
       "8016            0.0          1.0            0.0            1.0        1   \n",
       "8017            0.0          1.0            1.0            0.0        0   \n",
       "8018            0.0          1.0            1.0            0.0        1   \n",
       "\n",
       "        period  abyssinian  affen  airedale  akita  ...  tabby  tan_y  tick  \\\n",
       "0    -1.578521         0.0    0.0       0.0    0.0  ...    0.0    0.0   0.0   \n",
       "1    -0.701037         0.0    0.0       0.0    0.0  ...    1.0    0.0   0.0   \n",
       "2    -0.945517         0.0    0.0       0.0    0.0  ...    0.0    0.0   0.0   \n",
       "3    -0.527575         0.0    0.0       0.0    0.0  ...    0.0    0.0   0.0   \n",
       "4    -0.945517         0.0    0.0       0.0    0.0  ...    0.0    0.0   0.0   \n",
       "...        ...         ...    ...       ...    ...  ...    ...    ...   ...   \n",
       "8014 -0.109633         0.0    0.0       0.0    0.0  ...    0.0    0.0   0.0   \n",
       "8015  1.468008         0.0    0.0       0.0    0.0  ...    0.0    1.0   0.0   \n",
       "8016  0.805586         0.0    0.0       0.0    0.0  ...    0.0    0.0   0.0   \n",
       "8017 -1.578521         0.0    0.0       0.0    0.0  ...    1.0    0.0   0.0   \n",
       "8018  0.561106         0.0    0.0       0.0    0.0  ...    0.0    0.0   0.0   \n",
       "\n",
       "      tiger  torbie  tortie  tricolor  white  yellow  DateTime  \n",
       "0       0.0     1.0     0.0       0.0    0.0     0.0  0.992954  \n",
       "1       0.0     0.0     0.0       0.0    0.0     0.0 -0.507999  \n",
       "2       0.0     0.0     0.0       0.0    0.0     0.0  0.018370  \n",
       "3       0.0     0.0     0.0       0.0    0.0     0.0 -0.131035  \n",
       "4       0.0     0.0     0.0       0.0    0.0     0.0 -0.788962  \n",
       "...     ...     ...     ...       ...    ...     ...       ...  \n",
       "8014    0.0     0.0     0.0       0.0    0.5     0.0  0.463578  \n",
       "8015    0.0     0.0     0.0       0.0    0.0     0.0  1.201495  \n",
       "8016    0.0     0.0     0.0       0.0    0.0     0.5  0.001860  \n",
       "8017    0.0     0.0     0.0       0.0    0.0     0.0 -0.391051  \n",
       "8018    0.0     0.0     0.0       1.0    0.0     0.0  1.308984  \n",
       "\n",
       "[8019 rows x 270 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test, _, _ = preprocessing(test, models)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5bb1cd",
   "metadata": {},
   "source": [
    "# Модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e953eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8bb928",
   "metadata": {},
   "source": [
    "# LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d830ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [1, 5, 10],\n",
    "    'class_weight': ['balanced', None],\n",
    "}\n",
    "model1 = LogisticRegression(max_iter=500, random_state=1234)\n",
    "grid = GridSearchCV(LogisticRegression(), params, scoring=make_scorer(f1_score, average='macro'), cv=5)\n",
    "grid.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e14f2e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 10, 'class_weight': None}, 0.3978747228308211)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8e779206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49098441195295467"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = grid.best_estimator_\n",
    "model1.fit(X_train, y_train)\n",
    "f1_score(model1.predict(X_val), y_val, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc0a56",
   "metadata": {},
   "source": [
    "# Gradboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    max_iter=[50,100,150,200],\n",
    "    max_depth=[3,5,7],\n",
    "    'l2_regularization': [1, 2, 5],\n",
    "}\n",
    "model2 = GridSearchCV(HistGradientBoostingClassifier(random_state=1234), \n",
    "                      params, scoring=make_scorer(f1_score, average='macro'), cv=4)\n",
    "model2.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d3be37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingClassifier(l2_regularization=10, max_depth=7, max_iter=200,\n",
       "                               random_state=1234)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = HistGradientBoostingClassifier(max_iter=200, max_depth=7, l2_regularization=10, random_state=1234)\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8a7c26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7022235140241244, 0.6949645624458577)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(model2.predict(X_val), y_val, average='micro'), f1_score(model2.predict(X_val), y_val, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777121e",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6df968a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model2\n",
    "model.fit(X,y)\n",
    "y_test = model.predict(test)\n",
    "df_res = pd.DataFrame(data=y_test, columns=['Outcome'])\n",
    "df_res.index.rename('ID', inplace=True)\n",
    "df_res.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "245a0156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Animal Shelter Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/61.6k [00:00<?, ?B/s]\n",
      "100%|##########| 61.6k/61.6k [00:00<00:00, 87.7kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c animal-shelter-logs -f result.csv -m \"HistGradboost Reg 10 270 Better Upsample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46311f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
